# Vesuvius Challenge æ•°æ®å‡†å¤‡æŒ‡å—

**æ•°æ®é›†æè¿°**: 3D chunks of binary labeled CT scans of the closed and carbonized Herculaneum scrolls

**æ•°æ®æ¥æº**:
- ESRF synchrotron (Grenoble, France) - Beamline BM18
- DLS synchrotron (Oxford, UK) - Beamline I12

---

## âœ… æ•°æ®å‡†å¤‡æ£€æŸ¥æ¸…å•

### 1. æ•°æ®æ ¼å¼æ”¯æŒ âœ…

**å·²æ”¯æŒçš„æ ¼å¼**:
- âœ… `.zarr` - Zarr æ•°ç»„æ ¼å¼ï¼ˆæ¨èï¼Œé€‚åˆå¤§æ•°æ®ï¼‰
- âœ… `.npy` - NumPy æ•°ç»„æ ¼å¼
- âœ… `.tif/.tiff` - TIFF å †æ ˆæ ¼å¼

**å®ç°ä½ç½®**: `utils/dataset.py`

```python
def _load_volume(self, file_path):
    """æ”¯æŒ .zarr, .npy, .tif æ ¼å¼"""
    if file_path.suffix == '.zarr':
        volume = zarr.open(str(file_path), mode='r')
    elif file_path.suffix == '.npy':
        volume = np.load(str(file_path))
    elif file_path.suffix in ['.tif', '.tiff']:
        volume = imread(str(file_path))
```

### 2. 3D æ•°æ®å¤„ç† âœ…

**3D Patch æå–**:
- âœ… éšæœº patch é‡‡æ ·
- âœ… å¯é…ç½® patch å¤§å° (D, H, W)
- âœ… æ»‘åŠ¨çª—å£æ¨ç†ï¼ˆå¸¦é‡å ï¼‰

**å®ç°**:
```python
# è®­ç»ƒæ—¶ï¼šéšæœº patch
volume_patch, mask_patch = self._extract_random_patch(volume, mask)

# æ¨ç†æ—¶ï¼šæ»‘åŠ¨çª—å£
patch_coords = self._generate_patch_coords()  # å¸¦é‡å 
```

### 3. äºŒå€¼æ ‡æ³¨æ”¯æŒ âœ…

**æ ‡æ³¨ç±»å‹**: Binary labeled (0/1)
- âœ… è‡ªåŠ¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°
- âœ… ä¿æŒäºŒå€¼ç‰¹æ€§
- âœ… æ”¯æŒè½¯æ ‡ç­¾

**å®ç°**:
```python
mask = mask.astype(np.float32)  # è½¬æ¢ä¸ºæµ®ç‚¹
mask_tensor = torch.from_numpy(mask_patch).unsqueeze(0)
```

### 4. æ•°æ®å¢å¼º âœ…

**3D æ•°æ®å¢å¼º**:
- âœ… éšæœºç¿»è½¬ï¼ˆ3ä¸ªè½´ï¼‰
- âœ… éšæœºæ—‹è½¬ï¼ˆxy å¹³é¢ï¼‰
- âœ… å¼ºåº¦å˜æ¢ï¼ˆäº®åº¦/å¯¹æ¯”åº¦ï¼‰
- âœ… å¼¹æ€§å˜å½¢

**å®ç°**:
```python
def _augment_3d(self, volume, mask):
    # ç¿»è½¬
    if np.random.rand() > 0.5:
        volume = np.flip(volume, axis=axis)
    
    # æ—‹è½¬
    if np.random.rand() > 0.5:
        volume = np.rot90(volume, k=k, axes=(1, 2))
    
    # å¼ºåº¦å˜æ¢
    volume = volume * alpha + beta
    
    # å¼¹æ€§å˜å½¢
    volume = ndimage.map_coordinates(volume, indices)
```

### 5. æ•°æ®å½’ä¸€åŒ– âœ…

**å½’ä¸€åŒ–æ–¹æ³•**: Z-score normalization
- âœ… å‡å»å‡å€¼
- âœ… é™¤ä»¥æ ‡å‡†å·®
- âœ… å¯é€‰å¯ç”¨/ç¦ç”¨

**å®ç°**:
```python
def _normalize(self, volume):
    mean = volume.mean()
    std = volume.std()
    volume = (volume - mean) / std
```

---

## ğŸ“ é¢„æœŸæ•°æ®ç»“æ„

### è®­ç»ƒæ•°æ®

```
data/
â”œâ”€â”€ raw/                          # åŸå§‹ä¸‹è½½æ•°æ®
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ volume.zarr          # 3D CT æ‰«æ
â”‚   â”‚   â””â”€â”€ mask.zarr            # äºŒå€¼æ ‡æ³¨
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ volume.zarr
â”‚
â””â”€â”€ processed/                    # é¢„å¤„ç†åæ•°æ®
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ volume.npy           # æˆ– .zarr
    â”‚   â””â”€â”€ mask.npy
    â””â”€â”€ val/
        â”œâ”€â”€ volume.npy
        â””â”€â”€ mask.npy
```

### æ•°æ®æ–‡ä»¶è¯´æ˜

**volume.zarr / volume.npy**:
- ç±»å‹: 3D æ•°ç»„
- å½¢çŠ¶: (D, H, W) - æ·±åº¦ Ã— é«˜åº¦ Ã— å®½åº¦
- æ•°æ®ç±»å‹: float32
- å€¼èŒƒå›´: CT æ‰«æå¼ºåº¦å€¼
- æ¥æº: ESRF BM18 æˆ– DLS I12

**mask.zarr / mask.npy**:
- ç±»å‹: 3D æ•°ç»„
- å½¢çŠ¶: (D, H, W) - ä¸ volume ç›¸åŒ
- æ•°æ®ç±»å‹: float32 (0.0 æˆ– 1.0)
- å€¼: 0 = èƒŒæ™¯, 1 = çº¸èè‰çº¸è¡¨é¢
- æ ‡æ³¨: äºŒå€¼æ ‡ç­¾

---

## ğŸ”§ æ•°æ®åŠ è½½å™¨

### VesuviusDataset (è®­ç»ƒ)

```python
from utils.dataset import VesuviusDataset

dataset = VesuviusDataset(
    data_dir='data/processed/train',
    patch_size=(64, 64, 64),      # 3D patch å¤§å°
    augment=True,                  # å¯ç”¨æ•°æ®å¢å¼º
    normalize=True                 # å¯ç”¨å½’ä¸€åŒ–
)

# ä½¿ç”¨
volume, mask = dataset[0]
# volume: (1, 64, 64, 64)
# mask: (1, 64, 64, 64)
```

### VesuviusInferenceDataset (æ¨ç†)

```python
from utils.dataset import VesuviusInferenceDataset

dataset = VesuviusInferenceDataset(
    volume_path='data/test/volume.zarr',
    patch_size=(64, 64, 64),
    overlap=0.5,                   # 50% é‡å 
    normalize=True
)

# ä½¿ç”¨
for patch, coords in dataset:
    # patch: (1, 64, 64, 64)
    # coords: (d, h, w) èµ·å§‹åæ ‡
    prediction = model(patch)
```

---

## ğŸ“¥ æ•°æ®ä¸‹è½½

### æ–¹æ³• 1: ä½¿ç”¨ Kaggle APIï¼ˆæ¨èï¼‰

```bash
# 1. é…ç½® Kaggle API
mkdir -p ~/.kaggle
# ä¸Šä¼  kaggle.json

# 2. ä¸‹è½½æ•°æ®
python download_data.py
```

**download_data.py åŠŸèƒ½**:
- âœ… æ£€æŸ¥ Kaggle API é…ç½®
- âœ… ä¸‹è½½æ¯”èµ›æ•°æ®
- âœ… è‡ªåŠ¨è§£å‹
- âœ… æ˜¾ç¤ºæ•°æ®ç»“æ„

### æ–¹æ³• 2: æ‰‹åŠ¨ä¸‹è½½

```bash
# 1. è®¿é—®æ¯”èµ›é¡µé¢
https://www.kaggle.com/competitions/vesuvius-challenge-surface-detection/data

# 2. ä¸‹è½½æ•°æ®æ–‡ä»¶
# 3. è§£å‹åˆ° data/raw/
```

---

## ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½

```bash
# æµ‹è¯•æ•°æ®é›†
python utils/dataset.py
```

**é¢„æœŸè¾“å‡º**:
```
æµ‹è¯• Vesuvius æ•°æ®é›†...

1. æµ‹è¯•è®­ç»ƒæ•°æ®é›†
âœ“ æ‰¾åˆ° 1 ä¸ªæ•°æ®æ–‡ä»¶
   æ•°æ®é›†å¤§å°: 1
   Volume shape: torch.Size([1, 64, 64, 64])
   Mask shape: torch.Size([1, 64, 64, 64])
   Volume range: [-2.1234, 2.3456]
   Mask range: [0.0000, 1.0000]

2. æµ‹è¯•æ¨ç†æ•°æ®é›†
âœ“ åŠ è½½ä½“ç§¯: (128, 128, 128)
âœ“ ç”Ÿæˆ 64 ä¸ª patches
   æ•°æ®é›†å¤§å°: 64
   Patch shape: torch.Size([1, 64, 64, 64])
   Coordinates: (0, 0, 0)

âœ“ æ•°æ®é›†æµ‹è¯•é€šè¿‡
```

---

## âš ï¸ æ•°æ®è¦æ±‚æ£€æŸ¥

### ç¬¦åˆæ¯”èµ›è¦æ±‚ âœ…

| è¦æ±‚ | çŠ¶æ€ | å®ç° |
|------|------|------|
| 3D chunks | âœ… | æ”¯æŒ 3D æ•°ç»„ |
| Binary labeled | âœ… | æ”¯æŒäºŒå€¼æ ‡æ³¨ |
| CT scans | âœ… | å¤„ç† CT å¼ºåº¦å€¼ |
| ESRF/DLS data | âœ… | æ”¯æŒåŒæ­¥åŠ é€Ÿå™¨æ•°æ®æ ¼å¼ |
| Large volumes | âœ… | Zarr æ ¼å¼ + patch é‡‡æ · |

### æ•°æ®æ ¼å¼å…¼å®¹æ€§ âœ…

| æ ¼å¼ | æ”¯æŒ | æ¨è | è¯´æ˜ |
|------|------|------|------|
| .zarr | âœ… | â­â­â­â­â­ | å¤§æ•°æ®ï¼Œå¿«é€Ÿè¯»å– |
| .npy | âœ… | â­â­â­ | ä¸­ç­‰æ•°æ® |
| .tif | âœ… | â­â­ | å…¼å®¹æ€§å¥½ |

### æ•°æ®å¤„ç†èƒ½åŠ› âœ…

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| éšæœºé‡‡æ · | âœ… | è®­ç»ƒæ—¶é«˜æ•ˆ |
| æ»‘åŠ¨çª—å£ | âœ… | æ¨ç†æ—¶å®Œæ•´è¦†ç›– |
| æ•°æ®å¢å¼º | âœ… | 3D å¢å¼º |
| å½’ä¸€åŒ– | âœ… | Z-score |
| æ‰¹å¤„ç† | âœ… | DataLoader å…¼å®¹ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Step 1: ä¸‹è½½æ•°æ®

```bash
# é…ç½® Kaggle API
mkdir -p ~/.kaggle
# ä¸Šä¼  kaggle.json

# ä¸‹è½½
python download_data.py
```

### Step 2: æµ‹è¯•æ•°æ®åŠ è½½

```bash
# æµ‹è¯•
python utils/dataset.py
```

### Step 3: å¼€å§‹è®­ç»ƒ

```bash
# è®­ç»ƒ
python train.py --config configs/autodl_486_optimized.yaml
```

---

## ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼ˆé¢„æœŸï¼‰

### è®­ç»ƒé›†

- **ä½“ç§¯æ•°é‡**: ~10-20 ä¸ªå·è½´å—
- **æ¯ä¸ªä½“ç§¯å¤§å°**: ~1000Ã—1000Ã—1000 voxels
- **æ–‡ä»¶å¤§å°**: ~1-5 GB per volume
- **æ€»å¤§å°**: ~20-100 GB

### æµ‹è¯•é›†

- **ä½“ç§¯æ•°é‡**: ~5-10 ä¸ªå·è½´å—
- **æ¯ä¸ªä½“ç§¯å¤§å°**: ç±»ä¼¼è®­ç»ƒé›†
- **æ— æ ‡æ³¨**: ä»…æä¾› volume

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### 1. å†…å­˜ä¼˜åŒ–

```python
# ä½¿ç”¨ Zarrï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
volume = zarr.open('volume.zarr', mode='r')  # ä¸ç«‹å³åŠ è½½å…¨éƒ¨

# Patch é‡‡æ ·ï¼ˆå‡å°‘å†…å­˜ï¼‰
patch_size = (64, 64, 64)  # è€Œä¸æ˜¯åŠ è½½æ•´ä¸ªä½“ç§¯
```

### 2. é€Ÿåº¦ä¼˜åŒ–

```python
# ä½¿ç”¨å¤šè¿›ç¨‹åŠ è½½
DataLoader(
    dataset,
    batch_size=2,
    num_workers=8,      # å¤šè¿›ç¨‹
    pin_memory=True,    # å›ºå®šå†…å­˜
    prefetch_factor=4   # é¢„åŠ è½½
)
```

### 3. å­˜å‚¨ä¼˜åŒ–

```bash
# é¢„å¤„ç†åä¿å­˜ä¸º .zarr
# æ¯” .npy æ›´èŠ‚çœç©ºé—´ï¼Œè¯»å–æ›´å¿«
```

---

## âœ… æ€»ç»“

**æ•°æ®å‡†å¤‡å·¥ä½œå®Œæˆåº¦**: 100%

**å·²å®ç°**:
- âœ… æ”¯æŒ 3D CT æ‰«ææ•°æ®
- âœ… æ”¯æŒäºŒå€¼æ ‡æ³¨
- âœ… æ”¯æŒ ESRF/DLS æ•°æ®æ ¼å¼
- âœ… å®Œæ•´çš„æ•°æ®åŠ è½½å™¨
- âœ… 3D æ•°æ®å¢å¼º
- âœ… è®­ç»ƒå’Œæ¨ç†æ•°æ®é›†
- âœ… å†…å­˜ä¼˜åŒ–ï¼ˆpatch é‡‡æ ·ï¼‰

**ç¬¦åˆæ¯”èµ›è¦æ±‚**: âœ… å®Œå…¨ç¬¦åˆ

**å¯ä»¥å¼€å§‹è®­ç»ƒ**: âœ… æ˜¯

---

**æ•°æ®å‡†å¤‡å·¥ä½œå·²å®Œæˆï¼å¯ä»¥ä¸‹è½½æ•°æ®å¹¶å¼€å§‹è®­ç»ƒï¼** ğŸš€
