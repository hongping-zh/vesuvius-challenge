# AutoDL 320Â³ çœŸå®æµ‹è¯•æ•°æ®æ¨ç†æ–¹æ¡ˆ

## ğŸ“‹ ç›®æ ‡

åœ¨ AutoDL ä¸Šä½¿ç”¨ Kaggle çœŸå®çš„ **320Ã—320Ã—320** æµ‹è¯•æ•°æ®è¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆæ­£ç¡®å°ºå¯¸çš„ `prediction.tif`ï¼Œé¿å… resize å¯¼è‡´çš„ç²¾åº¦æŸå¤±ã€‚

---

## ğŸ” é—®é¢˜åˆ†æ

### å½“å‰çŠ¶æ€
- âŒ AutoDL ä¸Šçš„æµ‹è¯•æ•°æ®æ˜¯ **128Â³** (æ¥è‡ªè®­ç»ƒé›†çš„ä¸€ä¸ªæ ·æœ¬)
- âŒ Kaggle çœŸå®æµ‹è¯•æ•°æ®æ˜¯ **320Â³**
- âŒ ç”¨ 128Â³ æ¨ç† â†’ resize åˆ° 320Â³ â†’ ç²¾åº¦æŸå¤±

### ç›®æ ‡çŠ¶æ€
- âœ… ç›´æ¥åœ¨ 320Â³ æ•°æ®ä¸Šæ¨ç†
- âœ… è¾“å‡ºåŸç”Ÿ 320Â³ é¢„æµ‹ï¼Œæ— éœ€ resize
- âœ… æœ€å¤§åŒ–ä¿ç•™æ¨¡å‹ç²¾åº¦

---

## ğŸ“¦ æ–¹æ¡ˆä¸€ï¼šä¸‹è½½çœŸå®æµ‹è¯•æ•°æ®åˆ° AutoDLï¼ˆæ¨èï¼‰

### Step 1: åœ¨ Kaggle ä¸Šä¸‹è½½æµ‹è¯•æ•°æ®

#### 1.1 åˆ›å»ºä¸‹è½½ Notebook

åœ¨ Kaggle åˆ›å»ºæ–° Notebookï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ï¼š

```python
import tifffile as tiff
import numpy as np
from pathlib import Path

# è¯»å–æµ‹è¯•å›¾åƒ
test_img_path = "/kaggle/input/vesuvius-challenge-surface-detection/test_images/1407735.tif"
test_img = tiff.imread(test_img_path)

print(f"Test image shape: {test_img.shape}")  # (320, 320, 320)
print(f"Test image dtype: {test_img.dtype}")  # uint8

# ä¿å­˜ä¸º .npy æ ¼å¼ï¼ˆæ–¹ä¾¿ AutoDL åŠ è½½ï¼‰
output_path = Path("/kaggle/working/test_volume_320.npy")
np.save(output_path, test_img)
print(f"Saved to: {output_path}")
print(f"File size: {output_path.stat().st_size / 1e6:.2f} MB")
```

#### 1.2 ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°

è¿è¡Œå®Œæˆåï¼Œä» Notebook çš„ Output ä¸­ä¸‹è½½ `test_volume_320.npy`ï¼ˆçº¦ 32 MBï¼‰ã€‚

---

### Step 2: ä¸Šä¼ åˆ° AutoDL

#### 2.1 ä½¿ç”¨ SCP ä¸Šä¼ 

åœ¨æœ¬åœ° PowerShell è¿è¡Œï¼š

```powershell
# å‡è®¾ä½ çš„ AutoDL SSH ç«¯å£æ˜¯ 43898ï¼ˆä»æ§åˆ¶å°æŸ¥çœ‹ï¼‰
# æ›¿æ¢ <your-port> ä¸ºä½ çš„å®é™…ç«¯å£å·

scp -P <your-port> test_volume_320.npy root@connect.westb.seetacloud.com:/root/autodl-tmp/vesuvius-challenge/data/processed/test/
```

è¾“å…¥å¯†ç åç­‰å¾…ä¸Šä¼ å®Œæˆã€‚

#### 2.2 éªŒè¯ä¸Šä¼ æˆåŠŸ

SSH ç™»å½• AutoDLï¼Œè¿è¡Œï¼š

```bash
cd /root/autodl-tmp/vesuvius-challenge
ls -lh data/processed/test/test_volume_320.npy
```

åº”è¯¥çœ‹åˆ°æ–‡ä»¶å¤§å°çº¦ 32 MBã€‚

---

### Step 3: ä¿®æ”¹æ¨ç†è„šæœ¬

åœ¨ AutoDL ä¸Šç¼–è¾‘ `run_inference_autodl.py`ï¼š

#### 3.1 ä¿®æ”¹æµ‹è¯•æ•°æ®è·¯å¾„

æ‰¾åˆ°ç¬¬ 33 è¡Œï¼š

```python
# åŸä»£ç ï¼š
TEST_VOLUME_PATH = PROJECT_ROOT / "data" / "processed" / "test" / "volume.npy"

# æ”¹ä¸ºï¼š
TEST_VOLUME_PATH = PROJECT_ROOT / "data" / "processed" / "test" / "test_volume_320.npy"
```

#### 3.2 ä¿®æ”¹ patch sizeï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœä½ çš„æ¨¡å‹è®­ç»ƒæ—¶ç”¨çš„æ˜¯ 128Â³ patchï¼Œä¿æŒä¸å˜ï¼š

```python
patch_size = tuple(config.get("data", {}).get("patch_size", [128, 128, 128]))
```

æ¨¡å‹ä¼šç”¨æ»‘åŠ¨çª—å£åœ¨ 320Â³ æ•°æ®ä¸Šæ¨ç†ã€‚

#### 3.3 è°ƒæ•´ overlapï¼ˆå¯é€‰ï¼Œæé«˜ç²¾åº¦ï¼‰

åœ¨ `main()` å‡½æ•°ä¸­ï¼Œæ‰¾åˆ° `sliding_window_inference` è°ƒç”¨ï¼ˆçº¦ 267 è¡Œï¼‰ï¼š

```python
preds = sliding_window_inference(
    model=model,
    volume=volume,
    patch_size=patch_size,
    overlap=0.5,  # å¯ä»¥æ”¹ä¸º 0.75 æé«˜ç²¾åº¦ï¼Œä½†æ¨ç†æ—¶é—´æ›´é•¿
    batch_size=2,
    device=str(device),
    in_channels=config["model"].get("in_channels", 1),
)
```

**overlap å»ºè®®**ï¼š
- `0.5`ï¼šé»˜è®¤å€¼ï¼Œå¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦
- `0.75`ï¼šæ›´é«˜ç²¾åº¦ï¼Œæ¨ç†æ—¶é—´çº¦ 2 å€
- `0.25`ï¼šæ›´å¿«é€Ÿåº¦ï¼Œç²¾åº¦ç•¥ä½

---

### Step 4: è¿è¡Œæ¨ç†

åœ¨ AutoDL çš„ `torch_env` ç¯å¢ƒä¸­è¿è¡Œï¼š

```bash
conda activate torch_env
cd /root/autodl-tmp/vesuvius-challenge
python run_inference_autodl.py
```

#### é¢„æœŸè¾“å‡º

```
============================================================
AutoDL DynUNet One-click Inference
============================================================

Using device: cuda
Patch size: (128, 128, 128)
Loading weights: .../best_model.pth
Loading test volume: .../test_volume_320.npy
  Shape: (320, 320, 320)
  Range: [0.0000, 255.0000]
Total patches: 125  # 320Â³ ç”¨ 128Â³ patchï¼Œoverlap=0.5 æ—¶çº¦ 125 ä¸ª patch
Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [XX:XX<00:00]

Inference completed, prediction range: [0.0123, 0.9876]
Probability map saved to: predictions_dynunet.npy

Post-processing:
  Threshold: 0.3
  Prediction range: [0.0123, 0.9876]
  Positive ratio after threshold: 0.034567

Submission TIF generated: prediction.tif
  Shape: (320, 320, 320)  # âœ… æ­£ç¡®å°ºå¯¸ï¼
  Unique values: [0 1]
  Positive ratio: 0.034567

============================================================
One-click inference completed!
============================================================
Total time: 0h 15m  # æ—¶é—´ä¼šæ›´é•¿ï¼Œå› ä¸ºæ•°æ®æ›´å¤§
```

---

### Step 5: ä¸‹è½½ç»“æœ

#### 5.1 ä» AutoDL ä¸‹è½½

åœ¨æœ¬åœ° PowerShell è¿è¡Œï¼š

```powershell
scp -P <your-port> root@connect.westb.seetacloud.com:/root/autodl-tmp/vesuvius-challenge/prediction.tif ./prediction_320.tif
```

#### 5.2 éªŒè¯å°ºå¯¸

åœ¨æœ¬åœ°è¿è¡Œ Python éªŒè¯ï¼š

```python
import tifffile as tiff
import numpy as np

pred = tiff.imread("prediction_320.tif")
print(f"Shape: {pred.shape}")  # åº”è¯¥æ˜¯ (320, 320, 320)
print(f"Dtype: {pred.dtype}")  # åº”è¯¥æ˜¯ uint8
print(f"Unique values: {np.unique(pred)}")  # åº”è¯¥æ˜¯ [0, 1]
```

---

### Step 6: ä¸Šä¼ åˆ° Kaggle Dataset

#### 6.1 æ›´æ–° Kaggle Dataset

å¦‚æœä¹‹å‰çš„ Dataset å·²å­˜åœ¨ï¼Œåˆ›å»ºæ–°ç‰ˆæœ¬ï¼š

1. è®¿é—® https://www.kaggle.com/datasets/yourname/vesuvius-dynunet-prediction-tif
2. ç‚¹å‡» **New Version**
3. ä¸Šä¼ æ–°çš„ `prediction_320.tif`ï¼ˆæ›¿æ¢æ—§æ–‡ä»¶ï¼‰
4. æ·»åŠ ç‰ˆæœ¬è¯´æ˜ï¼š`Native 320^3 prediction without resize`
5. ç‚¹å‡» **Create**

#### 6.2 æ›´æ–° Kaggle Notebook

Notebook ä»£ç å¯ä»¥ç®€åŒ–ï¼ˆä¸éœ€è¦ resize äº†ï¼‰ï¼š

```python
import zipfile
from pathlib import Path

# ç›´æ¥å¤åˆ¶ï¼Œæ— éœ€ resize
src = Path("/kaggle/input/vesuvius-dynunet-prediction-tif/prediction.tif")
dst = Path("/kaggle/working/prediction.tif")

dst.write_bytes(src.read_bytes())
print("TIF copied to:", dst)
print("TIF size:", dst.stat().st_size, "bytes")

# åˆ›å»º submission.zip
zip_path = Path("/kaggle/working/submission.zip")
with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
    zf.write(dst, arcname="prediction.tif")

print("Submission zip created:", zip_path)
with zipfile.ZipFile(zip_path, "r") as zf:
    print("Files in zip:", zf.namelist())
```

---

## ğŸ“¦ æ–¹æ¡ˆäºŒï¼šç›´æ¥åœ¨ Kaggle Notebook ä¸­æ¨ç†ï¼ˆå¤‡é€‰ï¼‰

å¦‚æœ AutoDL æ•°æ®ä¼ è¾“éº»çƒ¦ï¼Œå¯ä»¥è€ƒè™‘ç›´æ¥åœ¨ Kaggle Notebook ä¸­è¿è¡Œæ¨ç†ã€‚

### ä¼˜ç‚¹
- âœ… æµ‹è¯•æ•°æ®å·²åœ¨ Kaggleï¼Œæ— éœ€ä¸‹è½½/ä¸Šä¼ 
- âœ… æ— éœ€åœ¨ AutoDL å’Œæœ¬åœ°ä¹‹é—´ä¼ è¾“æ–‡ä»¶
- âœ… GPU å…è´¹ï¼ˆæ¯å‘¨ 30 å°æ—¶ï¼‰

### ç¼ºç‚¹
- âŒ éœ€è¦ä¸Šä¼ æ¨¡å‹æƒé‡åˆ° Kaggle Dataset
- âŒ éœ€è¦åœ¨ Notebook ä¸­é‡æ–°å®ç°æ¨ç†ä»£ç 
- âŒ Kaggle GPU æ€§èƒ½å¯èƒ½ç•¥ä½äº AutoDLï¼ˆå–å†³äºå®ä¾‹ï¼‰

### å®ç°æ­¥éª¤ï¼ˆç®€è¦ï¼‰

1. **ä¸Šä¼ æ¨¡å‹åˆ° Kaggle Dataset**
   - ä» AutoDL ä¸‹è½½ `best_model.pth`
   - åˆ›å»º Kaggle Dataset ä¸Šä¼ 

2. **åˆ›å»ºæ¨ç† Notebook**
   - é“¾æ¥æ¨¡å‹ Dataset å’Œæµ‹è¯•æ•°æ® Dataset
   - å¤åˆ¶ `run_inference_autodl.py` çš„æ¨ç†é€»è¾‘
   - ç›´æ¥åœ¨ Kaggle GPU ä¸Šè¿è¡Œ

3. **ç”Ÿæˆæäº¤**
   - ç›´æ¥ä¿å­˜ `prediction.tif` å’Œ `submission.zip`

ï¼ˆå¦‚éœ€è¯¦ç»†æ­¥éª¤ï¼Œå‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥å±•å¼€ï¼‰

---

## ğŸ¯ æ¨èæµç¨‹æ€»ç»“

### æœ€ç®€æ–¹æ¡ˆï¼ˆæ¨èæ–°æ‰‹ï¼‰

1. âœ… åœ¨ Kaggle ä¸‹è½½ `test_volume_320.npy`
2. âœ… SCP ä¸Šä¼ åˆ° AutoDL
3. âœ… ä¿®æ”¹ `run_inference_autodl.py` çš„è·¯å¾„
4. âœ… è¿è¡Œæ¨ç†ï¼Œå¾—åˆ° 320Â³ é¢„æµ‹
5. âœ… ä¸‹è½½å¹¶æäº¤

### æœ€ä¼˜æ–¹æ¡ˆï¼ˆæ¨èç†Ÿç»ƒç”¨æˆ·ï¼‰

ç›´æ¥åœ¨ Kaggle Notebook ä¸­æ¨ç†ï¼ˆæ–¹æ¡ˆäºŒï¼‰ï¼Œé¿å…æ–‡ä»¶æ¥å›ä¼ è¾“ã€‚

---

## â±ï¸ æ—¶é—´ä¼°ç®—

| æ­¥éª¤ | æ—¶é—´ |
|-----|------|
| Kaggle ä¸‹è½½æµ‹è¯•æ•°æ® | 2 åˆ†é’Ÿ |
| SCP ä¸Šä¼ åˆ° AutoDL | 5-10 åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰|
| ä¿®æ”¹è„šæœ¬ | 2 åˆ†é’Ÿ |
| AutoDL æ¨ç†ï¼ˆ320Â³ï¼‰ | 15-30 åˆ†é’Ÿï¼ˆå–å†³äº GPUï¼‰|
| ä¸‹è½½ç»“æœ | 2 åˆ†é’Ÿ |
| ä¸Šä¼  Kaggle æäº¤ | 5 åˆ†é’Ÿ |
| **æ€»è®¡** | **çº¦ 30-50 åˆ†é’Ÿ** |

---

## ğŸ”§ å¯èƒ½çš„é—®é¢˜å’Œè§£å†³

### Q1: SCP ä¸Šä¼ å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**æ–¹æ¡ˆ A**ï¼šä½¿ç”¨ rsyncï¼ˆå¦‚æœæ”¯æŒï¼‰
```bash
rsync -avz -e "ssh -p <port>" test_volume_320.npy root@connect.westb.seetacloud.com:/root/autodl-tmp/vesuvius-challenge/data/processed/test/
```

**æ–¹æ¡ˆ B**ï¼šå‹ç¼©åä¸Šä¼ 
```bash
# æœ¬åœ°å‹ç¼©
gzip test_volume_320.npy

# ä¸Šä¼  .gz æ–‡ä»¶ï¼ˆæ›´å°ï¼‰
scp -P <port> test_volume_320.npy.gz root@...

# AutoDL ä¸Šè§£å‹
gunzip test_volume_320.npy.gz
```

**æ–¹æ¡ˆ C**ï¼šæ”¹ç”¨æ–¹æ¡ˆäºŒï¼ˆç›´æ¥åœ¨ Kaggle æ¨ç†ï¼‰

---

### Q2: AutoDL GPU å†…å­˜ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

è°ƒæ•´ `batch_size` å’Œ `patch_size`ï¼š

```python
# åœ¨ main() å‡½æ•°ä¸­
preds = sliding_window_inference(
    model=model,
    volume=volume,
    patch_size=(96, 96, 96),  # å‡å° patch size
    overlap=0.5,
    batch_size=1,  # å‡å° batch size
    device=str(device),
    in_channels=config["model"].get("in_channels", 1),
)
```

---

### Q3: æ¨ç†æ—¶é—´å¤ªé•¿æ€ä¹ˆåŠï¼Ÿ

- é™ä½ `overlap`ï¼š`0.5` â†’ `0.25`
- å¢å¤§ `batch_size`ï¼ˆå¦‚æœ GPU å†…å­˜å…è®¸ï¼‰
- ä½¿ç”¨æ›´å¿«çš„ GPUï¼ˆAutoDL å‡çº§å®ä¾‹ï¼‰

---

## ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### å­¦ä¹ é˜¶æ®µï¼ˆç°åœ¨ï¼‰

1. **é˜…è¯»æœ¬æ–‡æ¡£**ï¼Œç†è§£æ•´ä¸ªæµç¨‹
2. **å‡†å¤‡å·¥å…·**ï¼š
   - ç¡®ä¿æœ¬åœ°å®‰è£…äº† Python + tifffile
   - ç¡®ä¿èƒ½ SSH ç™»å½• AutoDL
   - ç¡®ä¿èƒ½è®¿é—® Kaggle

### æ‰§è¡Œé˜¶æ®µï¼ˆæ˜å¤©æˆ–å‡†å¤‡å¥½åï¼‰

1. **Kaggle ä¸‹è½½æµ‹è¯•æ•°æ®**ï¼ˆæ–¹æ¡ˆä¸€ Step 1ï¼‰
2. **ä¸Šä¼ åˆ° AutoDL**ï¼ˆæ–¹æ¡ˆä¸€ Step 2ï¼‰
3. **ä¿®æ”¹æ¨ç†è„šæœ¬**ï¼ˆæ–¹æ¡ˆä¸€ Step 3ï¼‰
4. **è¿è¡Œæ¨ç†**ï¼ˆæ–¹æ¡ˆä¸€ Step 4ï¼‰
5. **æäº¤åˆ° Kaggle**ï¼ˆæ–¹æ¡ˆä¸€ Step 5-6ï¼‰

---

## ğŸ“š å‚è€ƒèµ„æ–™

- Kaggle æµ‹è¯•æ•°æ®è·¯å¾„ï¼š`/kaggle/input/vesuvius-challenge-surface-detection/test_images/1407735.tif`
- AutoDL é¡¹ç›®è·¯å¾„ï¼š`/root/autodl-tmp/vesuvius-challenge/`
- SCP ä½¿ç”¨æ–‡æ¡£ï¼šhttps://linux.die.net/man/1/scp

---

**ç¥å­¦ä¹ é¡ºåˆ©ï¼æœ‰ä»»ä½•é—®é¢˜éšæ—¶é—®æˆ‘ã€‚** ğŸš€
