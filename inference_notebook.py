"""
Vesuvius Challenge Inference Notebook

ç”¨äº Kaggle Notebook æäº¤
- CPU only
- 9 å°æ—¶æ—¶é—´é™åˆ¶
- ä» Kaggle Dataset åŠ è½½æ¨¡å‹
- æ»‘åŠ¨çª—å£æ¨ç†
- æ‹“æ‰‘æ„ŸçŸ¥åå¤„ç†
- ç”Ÿæˆæäº¤æ–‡ä»¶
"""

import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
import time
from tqdm import tqdm
import pandas as pd


# ============================================================================
# æ¨¡å‹å®šä¹‰ï¼ˆå¤åˆ¶è‡ª models/unet3d.pyï¼‰
# ============================================================================

class DoubleConv3D(nn.Module):
    """åŒå·ç§¯å±‚"""
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm3d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        return self.double_conv(x)


class Down3D(nn.Module):
    """ä¸‹é‡‡æ ·å±‚"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool3d(2),
            DoubleConv3D(in_channels, out_channels)
        )
    
    def forward(self, x):
        return self.maxpool_conv(x)


class Up3D(nn.Module):
    """ä¸Šé‡‡æ ·å±‚"""
    def __init__(self, in_channels, out_channels, trilinear=True):
        super().__init__()
        
        if trilinear:
            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)
            self.conv = DoubleConv3D(in_channels + out_channels, out_channels)
        else:
            self.up = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv3D(in_channels, out_channels)
    
    def forward(self, x1, x2):
        x1 = self.up(x1)
        
        # å¤„ç†å°ºå¯¸ä¸åŒ¹é…
        import torch.nn.functional as F
        diffZ = x2.size()[2] - x1.size()[2]
        diffY = x2.size()[3] - x1.size()[3]
        diffX = x2.size()[4] - x1.size()[4]
        
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2,
                        diffZ // 2, diffZ - diffZ // 2])
        
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class UNet3D(nn.Module):
    """3D U-Net æ¨¡å‹"""
    def __init__(self, in_channels=1, out_channels=1, base_channels=32, trilinear=True):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.trilinear = trilinear
        
        # Encoder
        self.inc = DoubleConv3D(in_channels, base_channels)
        self.down1 = Down3D(base_channels, base_channels * 2)
        self.down2 = Down3D(base_channels * 2, base_channels * 4)
        self.down3 = Down3D(base_channels * 4, base_channels * 8)
        factor = 2 if trilinear else 1
        self.down4 = Down3D(base_channels * 8, base_channels * 16 // factor)
        
        # Decoder
        self.up1 = Up3D(base_channels * 16 // factor, base_channels * 8, trilinear)
        self.up2 = Up3D(base_channels * 8, base_channels * 4, trilinear)
        self.up3 = Up3D(base_channels * 4, base_channels * 2, trilinear)
        self.up4 = Up3D(base_channels * 2, base_channels, trilinear)
        
        # Output
        self.outc = nn.Conv3d(base_channels, out_channels, kernel_size=1)
    
    def forward(self, x):
        # Encoder
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        
        # Decoder
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        
        # Output
        logits = self.outc(x)
        return logits


# ============================================================================
# åå¤„ç†ï¼ˆç®€åŒ–ç‰ˆï¼‰
# ============================================================================

from scipy import ndimage
from skimage.morphology import remove_small_objects, remove_small_holes


def postprocess_prediction(pred, min_size=100, min_hole_size=50):
    """
    ç®€åŒ–çš„åå¤„ç†
    
    Parameters
    ----------
    pred : np.ndarray
        é¢„æµ‹æ©ç  (D, H, W)
    min_size : int
        æœ€å°ç»„ä»¶å¤§å°
    min_hole_size : int
        æœ€å°å­”æ´å¤§å°
    
    Returns
    -------
    np.ndarray
        åå¤„ç†åçš„æ©ç 
    """
    # è½¬æ¢ä¸ºå¸ƒå°”
    pred = pred.astype(bool)
    
    # ç§»é™¤å°ç»„ä»¶
    pred = remove_small_objects(pred, min_size=min_size, connectivity=2)
    
    # å¡«å……å°å­”æ´
    pred = remove_small_holes(pred, area_threshold=min_hole_size, connectivity=2)
    
    return pred.astype(np.float32)


# ============================================================================
# æ»‘åŠ¨çª—å£æ¨ç†
# ============================================================================

def sliding_window_inference(
    model,
    volume,
    patch_size=(64, 64, 64),
    overlap=0.5,
    batch_size=4,
    device='cpu'
):
    """
    æ»‘åŠ¨çª—å£æ¨ç†
    
    Parameters
    ----------
    model : nn.Module
        è®­ç»ƒå¥½çš„æ¨¡å‹
    volume : np.ndarray
        è¾“å…¥ä½“ç§¯ (D, H, W)
    patch_size : tuple
        Patch å¤§å°
    overlap : float
        é‡å æ¯”ä¾‹
    batch_size : int
        æ‰¹æ¬¡å¤§å°
    device : str
        è®¾å¤‡
    
    Returns
    -------
    np.ndarray
        é¢„æµ‹ç»“æœ (D, H, W)
    """
    D, H, W = volume.shape
    pd, ph, pw = patch_size
    
    # è®¡ç®—æ­¥é•¿
    stride_d = int(pd * (1 - overlap))
    stride_h = int(ph * (1 - overlap))
    stride_w = int(pw * (1 - overlap))
    
    # ç”Ÿæˆ patch åæ ‡
    patches = []
    for d in range(0, D - pd + 1, stride_d):
        for h in range(0, H - ph + 1, stride_h):
            for w in range(0, W - pw + 1, stride_w):
                patches.append((d, h, w))
    
    print(f"æ€»å…± {len(patches)} ä¸ª patches")
    
    # è¾“å‡ºç´¯ç§¯
    output = np.zeros((D, H, W), dtype=np.float32)
    counts = np.zeros((D, H, W), dtype=np.float32)
    
    # æ‰¹æ¬¡æ¨ç†
    model.eval()
    model.to(device)
    
    with torch.no_grad():
        for i in tqdm(range(0, len(patches), batch_size), desc="æ¨ç†ä¸­"):
            batch_patches = patches[i:i + batch_size]
            
            # æå– patches
            batch_data = []
            for d, h, w in batch_patches:
                patch = volume[d:d+pd, h:h+ph, w:w+pw]
                batch_data.append(patch)
            
            # è½¬æ¢ä¸º tensor
            batch_tensor = torch.from_numpy(np.array(batch_data)).float()
            batch_tensor = batch_tensor.unsqueeze(1)  # (B, 1, D, H, W)
            batch_tensor = batch_tensor.to(device)
            
            # æ¨ç†
            pred = model(batch_tensor)
            pred = torch.sigmoid(pred)
            pred = pred.cpu().numpy()
            
            # ç´¯ç§¯ç»“æœ
            for j, (d, h, w) in enumerate(batch_patches):
                output[d:d+pd, h:h+ph, w:w+pw] += pred[j, 0]
                counts[d:d+pd, h:h+ph, w:w+pw] += 1
    
    # å¹³å‡
    output = output / (counts + 1e-8)
    
    return output


# ============================================================================
# ä¸»æ¨ç†æµç¨‹
# ============================================================================

def main():
    """ä¸»æ¨ç†å‡½æ•°"""
    print("=" * 60)
    print("Vesuvius Challenge Inference")
    print("=" * 60)
    print()
    
    start_time = time.time()
    
    # ========================================
    # 1. åŠ è½½æ¨¡å‹
    # ========================================
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    
    # Kaggle Dataset è·¯å¾„ï¼ˆéœ€è¦ä¿®æ”¹ä¸ºå®é™…è·¯å¾„ï¼‰
    model_path = '/kaggle/input/vesuvius-model/best_model.pth'
    
    # å¦‚æœæœ¬åœ°æµ‹è¯•ï¼Œä½¿ç”¨æœ¬åœ°è·¯å¾„
    if not Path(model_path).exists():
        model_path = 'models/checkpoints/best_model.pth'
    
    # åˆ›å»ºæ¨¡å‹
    model = UNet3D(in_channels=1, out_channels=1, base_channels=48)
    
    # åŠ è½½æƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if Path(model_path).exists():
        checkpoint = torch.load(model_path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
        print(f"  Epoch: {checkpoint.get('epoch', 'N/A')}")
        print(f"  Best Score: {checkpoint.get('best_dice', 'N/A'):.4f}")
    else:
        print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        print(f"   (ä»…ç”¨äºæµ‹è¯•æ¨ç†æµç¨‹)")
    
    model.eval()
    
    # ========================================
    # 2. åŠ è½½æµ‹è¯•æ•°æ®
    # ========================================
    print("\nğŸ“¥ åŠ è½½æµ‹è¯•æ•°æ®...")
    
    # Kaggle æµ‹è¯•æ•°æ®è·¯å¾„
    test_path = '/kaggle/input/vesuvius-challenge-surface-detection/test/volume.zarr'
    
    # å¦‚æœæœ¬åœ°æµ‹è¯•
    if not Path(test_path).exists():
        test_path = 'data/processed/test/volume.npy'
    
    # åŠ è½½æ•°æ®
    if test_path.endswith('.zarr'):
        import zarr
        volume = zarr.open(test_path, mode='r')
        volume = np.array(volume)
    else:
        volume = np.load(test_path)
    
    volume = volume.astype(np.float32)
    
    print(f"âœ“ æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ")
    print(f"  å½¢çŠ¶: {volume.shape}")
    print(f"  èŒƒå›´: [{volume.min():.4f}, {volume.max():.4f}]")
    
    # å½’ä¸€åŒ–
    mean = volume.mean()
    std = volume.std()
    volume = (volume - mean) / (std + 1e-8)
    
    # ========================================
    # 3. æ¨ç†
    # ========================================
    print("\nğŸ”® å¼€å§‹æ¨ç†...")
    
    predictions = sliding_window_inference(
        model=model,
        volume=volume,
        patch_size=(80, 80, 80),
        overlap=0.5,
        batch_size=4,
        device='cpu'
    )
    
    print(f"âœ“ æ¨ç†å®Œæˆ")
    print(f"  é¢„æµ‹èŒƒå›´: [{predictions.min():.4f}, {predictions.max():.4f}]")
    
    # ========================================
    # 4. åå¤„ç†
    # ========================================
    print("\nğŸ”§ åå¤„ç†...")
    
    # äºŒå€¼åŒ–
    predictions_binary = (predictions > 0.5).astype(np.float32)
    
    # æ‹“æ‰‘ä¿®æ­£
    predictions_final = postprocess_prediction(
        predictions_binary,
        min_size=100,
        min_hole_size=50
    )
    
    print(f"âœ“ åå¤„ç†å®Œæˆ")
    print(f"  é¢„æµ‹åƒç´ : {predictions_final.sum():.0f} / {predictions_final.size}")
    print(f"  è¦†ç›–ç‡: {predictions_final.mean() * 100:.2f}%")
    
    # ========================================
    # 5. ç”Ÿæˆæäº¤æ–‡ä»¶
    # ========================================
    print("\nğŸ“¤ ç”Ÿæˆæäº¤æ–‡ä»¶...")
    
    # åˆ›å»ºæäº¤ DataFrameï¼ˆæ ¹æ®æ¯”èµ›è¦æ±‚è°ƒæ•´æ ¼å¼ï¼‰
    # è¿™é‡Œæ˜¯ç¤ºä¾‹æ ¼å¼ï¼Œéœ€è¦æ ¹æ®å®é™…æ¯”èµ›è¦æ±‚ä¿®æ”¹
    submission = pd.DataFrame({
        'id': ['sample_id'],  # æ›¿æ¢ä¸ºå®é™… ID
        'prediction': [predictions_final.flatten().tolist()]  # æˆ–å…¶ä»–æ ¼å¼
    })
    
    submission.to_csv('submission.csv', index=False)
    
    print(f"âœ“ æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: submission.csv")
    
    # ========================================
    # æ€»ç»“
    # ========================================
    elapsed_time = time.time() - start_time
    hours = int(elapsed_time // 3600)
    minutes = int((elapsed_time % 3600) // 60)
    
    print("\n" + "=" * 60)
    print("âœ… æ¨ç†å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»è€—æ—¶: {hours}h {minutes}m")
    print(f"æ—¶é—´é™åˆ¶: 9h (å‰©ä½™: {9 - hours}h {60 - minutes}m)")
    
    if elapsed_time < 9 * 3600:
        print("âœ“ åœ¨æ—¶é—´é™åˆ¶å†…å®Œæˆ")
    else:
        print("âš ï¸ è¶…è¿‡æ—¶é—´é™åˆ¶ï¼")


if __name__ == "__main__":
    main()
