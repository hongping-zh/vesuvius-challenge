"""
æµ‹è¯•æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))


def test_ink_sampling():
    """æµ‹è¯• Ink-only Sampling"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: Ink-only Sampling")
    print("="*60)
    
    try:
        from utils.ink_sampling import InkAwareVesuviusDataset
        print("âœ… å¯¼å…¥æˆåŠŸ")
        
        # æ³¨æ„ï¼šéœ€è¦çœŸå®æ•°æ®æ‰èƒ½æµ‹è¯•
        print("âš ï¸  éœ€è¦çœŸå®æ•°æ®æ‰èƒ½å®Œæ•´æµ‹è¯•")
        print("   æ•°æ®è·¯å¾„: data/processed/train/")
        
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_multi_channel():
    """æµ‹è¯•å¤šé€šé“ç‰¹å¾"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: å¤šé€šé“ç‰¹å¾æå–")
    print("="*60)
    
    try:
        from utils.multi_channel import extract_multi_channel_features, get_channel_count
        import numpy as np
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        volume = np.random.rand(64, 64, 64).astype(np.float32)
        
        # æµ‹è¯•ä¸åŒé€šé“ç»„åˆ
        test_configs = [
            ['raw'],
            ['raw', 'grad'],
            ['raw', 'grad', 'log'],
        ]
        
        for channels in test_configs:
            features = extract_multi_channel_features(volume, channels)
            expected_channels = get_channel_count(channels)
            
            print(f"\né€šé“é…ç½®: {channels}")
            print(f"  è¾“å‡ºå½¢çŠ¶: {features.shape}")
            print(f"  é¢„æœŸé€šé“: {expected_channels}")
            print(f"  å®é™…é€šé“: {features.shape[0]}")
            
            assert features.shape[0] == expected_channels, "é€šé“æ•°ä¸åŒ¹é…ï¼"
        
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_dynamic_loss():
    """æµ‹è¯•åŠ¨æ€ Loss è°ƒåº¦"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: åŠ¨æ€ Loss æƒé‡è°ƒåº¦")
    print("="*60)
    
    try:
        from utils.dynamic_loss import DynamicLossScheduler
        
        scheduler = DynamicLossScheduler(
            total_epochs=50,
            warmup_epochs=20,
            strategy='two_stage'
        )
        
        # æµ‹è¯•å…³é”® epoch
        test_epochs = [0, 10, 19, 20, 30, 49]
        
        print(f"\n{'Epoch':<8} {'Dice':<8} {'BCE':<8} {'Surface':<10} {'Topology':<10}")
        print("-"*60)
        
        for epoch in test_epochs:
            weights = scheduler.get_weights(epoch)
            print(f"{epoch:<8} {weights['dice']:<8.3f} {weights['bce']:<8.3f} "
                  f"{weights['surface']:<10.3f} {weights['topology']:<10.3f}")
            
            # éªŒè¯æƒé‡
            if epoch < 20:
                assert weights['surface'] == 0.0, f"Epoch {epoch} surface åº”è¯¥ä¸º 0"
                assert weights['topology'] == 0.0, f"Epoch {epoch} topology åº”è¯¥ä¸º 0"
            else:
                assert weights['surface'] > 0.0, f"Epoch {epoch} surface åº”è¯¥ > 0"
                assert weights['topology'] > 0.0, f"Epoch {epoch} topology åº”è¯¥ > 0"
        
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_config_loading():
    """æµ‹è¯•ä¼˜åŒ–é…ç½®åŠ è½½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: ä¼˜åŒ–é…ç½®æ–‡ä»¶")
    print("="*60)
    
    try:
        import yaml
        
        config_path = Path(__file__).parent / 'configs' / 'autodl_dynunet_optimized.yaml'
        
        if not config_path.exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        print(f"\né…ç½®æ–‡ä»¶: {config_path.name}")
        print(f"\næ¨¡å‹é…ç½®:")
        print(f"  ç±»å‹: {config['model']['type']}")
        print(f"  è¾“å…¥é€šé“: {config['model']['in_channels']}")
        print(f"  åŸºç¡€ç‰¹å¾: {config['model']['base_num_features']}")
        
        print(f"\næ•°æ®é…ç½®:")
        print(f"  æ•°æ®é›†ç±»å‹: {config['data']['dataset_type']}")
        print(f"  é€šé“: {config['data']['channels']}")
        print(f"  Patch Size: {config['data']['patch_size']}")
        print(f"  Positive Ratio: {config['data']['positive_ratio']}")
        
        print(f"\nè®­ç»ƒé…ç½®:")
        print(f"  Epochs: {config['training']['epochs']}")
        print(f"  Batch Size: {config['training']['batch_size']}")
        print(f"  åŠ¨æ€ Loss: {config['training']['use_dynamic_loss']}")
        print(f"  Warmup Epochs: {config['training']['warmup_epochs']}")
        
        print(f"\nåå¤„ç†é…ç½®:")
        print(f"  Multi-Threshold: {config['postprocessing']['multi_threshold']}")
        print(f"  Thresholds: {config['postprocessing']['thresholds']}")
        
        # éªŒè¯å…³é”®é…ç½®
        assert config['model']['in_channels'] == 5, "è¾“å…¥é€šé“åº”è¯¥æ˜¯ 5"
        assert config['data']['dataset_type'] == 'ink_aware', "åº”è¯¥ä½¿ç”¨ ink_aware"
        assert config['data']['patch_size'] == [128, 128, 128], "Patch åº”è¯¥æ˜¯ 128Â³"
        assert config['training']['use_dynamic_loss'] == True, "åº”è¯¥å¯ç”¨åŠ¨æ€ Loss"
        
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("ä¼˜åŒ–åŠŸèƒ½å®Œæ•´æµ‹è¯•")
    print("="*60)
    
    results = []
    
    # æµ‹è¯• 1: Ink-only Sampling
    results.append(("Ink-only Sampling", test_ink_sampling()))
    
    # æµ‹è¯• 2: å¤šé€šé“ç‰¹å¾
    results.append(("å¤šé€šé“ç‰¹å¾", test_multi_channel()))
    
    # æµ‹è¯• 3: åŠ¨æ€ Loss
    results.append(("åŠ¨æ€ Loss è°ƒåº¦", test_dynamic_loss()))
    
    # æµ‹è¯• 4: é…ç½®åŠ è½½
    results.append(("ä¼˜åŒ–é…ç½®æ–‡ä»¶", test_config_loading()))
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
    
    passed = sum(1 for _, r in results if r)
    total = len(results)
    
    print(f"\né€šè¿‡: {passed}/{total}")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. å‡†å¤‡çœŸå®æ•°æ®")
        print("2. åœ¨ AutoDL ä¸Šå¿«é€ŸéªŒè¯ï¼ˆ8 epochsï¼‰")
        print("3. python train.py --config configs/autodl_dynunet_optimized.yaml")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    # ç¯å¢ƒè‡ªæ£€ï¼ˆMONAI / Torch / GPUï¼‰
    print("\n" + "-" * 60)
    print("ç¯å¢ƒè‡ªæ£€ (MONAI / Torch / GPU)")
    print("-" * 60)
    try:
        import monai  # type: ignore
        import torch  # type: ignore

        print(f"MONAI ç‰ˆæœ¬: {monai.__version__}")
        print(f"Torch ç‰ˆæœ¬: {torch.__version__}")

        if not torch.cuda.is_available():
            print("âŒ CUDA ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ GPU é©±åŠ¨ / CUDA å®‰è£…")
        else:
            props = torch.cuda.get_device_properties(0)
            total_gb = props.total_memory / 1e9
            print(f"GPU: {props.name}, æ˜¾å­˜: {total_gb:.1f} GB")
            if props.total_memory <= 30e9:
                print("âš ï¸ GPU æ˜¾å­˜ <= 30GBï¼Œå¯èƒ½æ— æ³•å®‰å…¨è·‘ 128Â³ Patch + å¤§æ¨¡å‹")
            else:
                print("âœ… GPU æ˜¾å­˜æ»¡è¶³ 128Â³ Patch + DynUNet è®­ç»ƒéœ€æ±‚")
    except Exception as e:  # pragma: no cover - ä»…ä½œè¿è¡Œç¯å¢ƒæç¤º
        print(f"âš ï¸ ç¯å¢ƒè‡ªæ£€å‡ºé”™: {e}")

    # å¯é€‰ï¼šæ£€æŸ¥åå¤„ç†ä¼˜åŒ–è„šæœ¬æ˜¯å¦å¯ç”¨
    print("\n" + "-" * 60)
    print("åå¤„ç†ä¼˜åŒ–è„šæœ¬å¯ç”¨æ€§æ£€æŸ¥ (optimize_postprocessing.py)")
    print("-" * 60)
    try:
        import optimize_postprocessing  # type: ignore

        print("âœ… æˆåŠŸå¯¼å…¥ optimize_postprocessing æ¨¡å—")
        if hasattr(optimize_postprocessing, "main"):
            print("   æç¤º: å¯åœ¨è®­ç»ƒåè¿è¡Œ `python optimize_postprocessing.py` å¯¹é˜ˆå€¼/åå¤„ç†åšç½‘æ ¼æœç´¢")
        else:
            print("   æ³¨æ„: æ¨¡å—ä¸­æœªæ‰¾åˆ° main() å‡½æ•°ï¼Œå¦‚éœ€ä¸€é”®è¿è¡Œå¯åç»­æ·»åŠ å…¥å£å‡½æ•°")
    except Exception as e:  # pragma: no cover - ä»…ä½œè¿è¡Œç¯å¢ƒæç¤º
        print(f"âš ï¸ æ— æ³•å¯¼å…¥ optimize_postprocessing: {e}")

    print("="*60)


if __name__ == "__main__":
    main()
